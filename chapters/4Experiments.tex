\chapter{Empirical Experiments}\label{chapter:experiments}
% \setcounter{page}{0}
% \pagenumbering{arabic}

\section{Prices and Filling Information}
To have a comprehensive understanding of how trades in trade book correspond to orders in order book, Figure~\ref{fig:p_f_i} provides an overview of the whole active trading hours from 10:00 am to 4:00 pm on 31st January. It shows how filled price in the trade book track the mid-price in the order book, the distribution of passive and aggressive trades, and the spread range for each trade. The lower subplot presents the filled volume for each trading record.
\begin{figure}[h]
    \centering
    \includegraphics[width=1\linewidth]{figures/Prices and Filling Information.png}
    \caption{Prices and filling information. This plot shows the mid-price from the order book (blue line), trade book filled prices (red line), and spread (yellow shading). Passive trades (green dots) and aggressive trades (red dots) are highlighted. The bottom panel represents the filled volume over time.}
    \label{fig:p_f_i}
\end{figure}
As can be seen in Figure~\ref{fig:p_f_i}, the mid-price has the highest point between 14:00 and 15:00. The filled price fits the mid-price well. We can see there are a lot of red dots which shows that they are aggressive trades. We didn't classify bid or ask side because it's not the research target in the thesis. These aggressive trades go outside the spread range. The size of dots stands for relative volume of the trades. In other words, when the volume is large compared to other timestamps, the size of the dot will be larger. Therefore, we can easily see the active trading time point in the plot. Moreover, red dots represent aggressive trades in the trade book. We can see the red dots are more than green ones, which indicates that a lot of orders get filled by aggressive traders taking out them of the order book, instead of passively waiting for the market movements. This aligns with our need to improve the backtesting environment by predicting aggressive trades across the order book. Specially, there are several sparks in the trend of mid-price in the order book. These are caused by...

From the bottom panel, in the beginning of 10:00, 15:45, 14:11, there are high volume up to 2,000,000, which are higher than common volume 1,000,000. At 13:45, the highest trading volume occurs as 3,000,000. Combined the two plots together, we can see when there's a drop, it's often accompanied by many trading records or large trades. 

\begin{figure}[h]
    \centering
    \includegraphics[width=1\linewidth]{figures/Filtered Prices and Filling Information.png}
    \caption{Filtered prices and filling information. Similar to Figure~\ref{fig:p_f_i}, but filtering sharp jump points. The price and trade dynamics remain the same, without increased variability for better general trend capture}
    \label{fig:f_p_f_i}
\end{figure}

In the Figure~\ref{fig:f_p_f_i} after filtering 1,232 sparks in the data, we can clearly see some clustering for both passive and aggressive trades. For example, in the beginning of 10:00, many passive trades gather here. It may because there's a sharp dropping movement in the market, many limit orders are filled. Furthermore, many aggressive trades gather around  


% Evaluating how well the model captures aggressive trades movements and distribution.
% Market realism (stylized facts: price impact, spread, volume clustering).

\section{Prediction Results}
The prediction framework consists of three sequential stages. The first stage employs an XGBoost model to identify potential aggressive trade timestamps while reducing the overall dataset size. The second stage is GRU networks. It serves as a bridge between machine learning approaches and stochastic processes. It generates hidden states as neural kernels. The final stage implements a neural Hawkes process that estimates event intensity. In the end this approach produces a detailed and interpretable decision of predictions for aggressive trading events.

We present the prediction results of each stage using a representative trading day. The training dataset consists of the whole trading day from January 31, 2025, 10:00:00 to 15:59:59 PM, containing 307,764 rows. This day is chosen because it contains lots of market information and trade data, which is the most comprehensive trading day across the whole dataset. 

The testing datasets are some 30-minute, 1-hour windows from different trading days, each with around 20,000 rows. This specific time window was selected as it represents a commonly used timeframe for FX trading backtesting within the MN platform.

\subsection{XGBoost Stage: With and Without KMeansSMOTE}

KMeansSMOTE, introduced in Chapter~\ref{chapter:methodology}, is an oversampling technique designed to address class imbalance in training data. We compare the XGBoost prediction results with and without KMeansSMOTE to evaluate the influence of oversampling. The impact of applying this oversampling method on both class balance and prediction quality is analyzed.

We first present the classification results of XGBoost trained with KMeansSMOTE. The KMeansSMOTE configuration is as follows:

\begin{verbatim}
pipeline = Pipeline([
("imputer", SimpleImputer(strategy="median")),
("smote", KMeansSMOTE(random_state=42,
cluster_balance_threshold=0.02,
kmeans_estimator=KMeans(n_clusters=200, random_state=42),
sampling_strategy=0.5))
])
\end{verbatim}

The median strategy fills missing values with the median of each feature. A cluster balance threshold of 0.02 ensures oversampling is done in 'safe' areas where there are at least some genuine minority examples. As a result, the training set has the ratio of 3:7 about class 1 and class 0. It significantly increases the class balance from 1:499 in Figure~\ref{fig: aflag_class_distribution}.

% !!maybe need refinement
This step is aimed to get a model to initially find out as many positives as possible by keeping recall as 0.6 without losing precision. So, the input for testing only depends on market features ($S$, $M$, $V_A^{1}$, $V_A^{1}$, $\bar{\delta}_S$, $\bar{\delta}_M$, $\sigma_S$, $\sigma_M$, $r_V$), and the output contains the shortened training dataset for the next step with aggressive trade candidates. The filtered output also gets rebalanced towards class 1 because we filter out those are not predicted as 1. the bias toward class 0 and helps the model learn better from the underrepresented class 1.

As shown in Figure~\ref{fig:xgb-pred-vs-true-km}, the model catches many true positives. The class balancing done by KMeansSMOTE reduces the bias toward class 0 and helps the model learn better from the underrepresented class 1.

Table~\ref{tab:xgb-confusion-km} shows the confusion matrix. 4,011 are predicted as class 0 (non-aggressive trade), and 3,739 are predicted as class 1. The model correctly finds 13 true positives and 4,001 true negatives. The dataset size drops from 7,750 to 3,739 rows, which is 51.75\% of the original. This helps improve speed and keeps most of the important trade points.

Moreover, Table~\ref{tab:xgb-classification-report-km} shows the detailed classification report. We mainly care about the prediction performance for class 1, since this is the main goal of the whole research. The precision of class 0 is not meaningful here because the original data is extremely imbalanced. Although the precision for class 1 is still very low at 0.0035, the recall reaches 0.5652. This means the model finds sufficient true trades under the model with oversampling. This makes preparation for next neural Hawkes process.


\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/aflag_XGBoost_181330.png}
    \caption{Comparison of true vs. predicted $\bar{\alpha}$ from XGBoost with KMeansSMOTE. 
    The blue '+' markers show the true class labels, and the orange '+' markers show the predicted ones. To make the plot easier to read, the predicted values are moved down by 0.05 on the y-axis. This small shift helps to see clearly how well the predictions match the true labels.
    }
    \label{fig:xgb-pred-vs-true-km}
\end{figure}

\begin{table}[H]
    \centering
    \caption{Confusion matrix of XGBoost with KMeansSMOTE}
    \label{tab:xgb-confusion-km}
    \begin{tabular}{lcc}
        \toprule
        & Predicted 0 & Predicted 1 \\
        \midrule
        True 0 & 4,001 & 3,726 \\
        True 1 & 10 & 13 \\
        \bottomrule
    \end{tabular}
\end{table}
\begin{table}[H]
    \centering
    \caption{Classification report of XGBoost with KMeansSMOTE}
    \label{tab:xgb-classification-report-km}
    \begin{tabular}{lcccc}
        \toprule
        Class & Precision & Recall & F1-score & Support \\
        \midrule
        0 & 0.9962 & 0.5178 & 0.6817 & 7727 \\
        1 & 0.0035 & 0.5652 & 0.0069 & 23 \\
        \midrule
        Accuracy & \multicolumn{4}{c}{0.5179} \\
        \bottomrule
    \end{tabular}
\end{table}

Without KMeansSMOTE, even if we reach the same recall, the precision is even worse (only 0.0019). That means almost all predicted class 1 are wrong. The F1-score is just 0.0038, which is only half of the score from XGBoost with KMeansSMOTE. Also, the filter effect is weaker. More lines (5,065) are left in the result, which makes the next detection step slower and more difficult. So using KMeansSMOTE helps not only improve model performance but also makes the pipeline more efficient.

\begin{table}[H]
    \centering
    \caption{Confusion matrix of XGBoost without KMeansSMOTE}
    \label{tab:xgb-noKM}
    \begin{tabular}{lccc}
        \toprule
        Class & Precision & Recall & F1-score\\
        \midrule
        1 & 0.0019 & 0.5881 & 0.0038 \\        
        \bottomrule
    \end{tabular}
\end{table}

These results show that KMeansSMOTE gives significant improvement when dealing with extreme class imbalance, especially in terms of F1-score. We can also infer from the classification evaluation that single XGBoost is not enough for the prediction task even with resampling methods. The large set of candidate points predicted at this stage will be passed to the next neural Hawkes model, which helps to further clean and refine the aggressive trade signals. 


%------------- Neural Hawkes process -------------
\subsection{Neural Hawkes Process Results}
We use the GRU model as a neural kernel to generate hidden states, which are then used in the Hawkes process. The estimation is performed on the dataset from January 31, 2025, between 10:00:00 and 15:59:59. This period is the same as the XGBoost training set, but the data is filtered using the anomaly detection function in Algorithm~\ref{al: window-based} to reduce class imbalance.

In the estimation stage, the GRU is trained as mentioned in Chapter~\ref{chapter:methodology} and hidden states \( h_t \) are extracted. These hidden states are passed to the Hawkes intensity formula in Equation~\ref{eq:intensity}. We estimate the parameters by minimizing the negative log-likelihood using the L-BFGS-B method. The optimization process completed in 363.98 seconds, the final negative log-likelihood reached $-8261.28$, and success flag returned \texttt{True} which means it successfully get convergence. The estimated results are as follows:
\begin{table}[H]
    \centering
    \caption{Estimated Parameters of the Neural Hawkes Process}
    \label{tb:hawkes-params}
    \begin{tabular}{lcc}
    \toprule
    \textbf{Parameter} & \textbf{Type 0 (Non-Aggressive)} & \textbf{Type 1 (Aggressive)} \\
    \midrule
    \multicolumn{3}{l}{\textbf{Baseline Intensity} (\( \mu \))} \\
    \quad Value & 0.0677 & 0.0029 \\
    \midrule
    \multicolumn{3}{l}{\textbf{Excitation Matrix} (\( \alpha \))} \\
    \quad From Type 0 & 10.12 & 0.52 \\
    \quad From Type 1 & 15.85 & 2.57 \\
    \midrule
    \multicolumn{3}{l}{\textbf{Decay Matrix} (\( \beta \))} \\
    \quad From Type 0 & 10.55 & 62.32 \\
    \quad From Type 1 & 18.48 & 14.76 \\
    \bottomrule
    \end{tabular}
\end{table}

Results of the baseline intensity $\mu$ mean the natural chance of non-aggressive trade is higher than aggressive trade mean without any past event influence. In our case, non-aggressive trades are more likely to occur by default with $\mu_0 = 0.0677$, while aggressive trades are rare ($\mu_1 = 0.0029$) and usually triggered by certain market activity otherwise less easy to happen naturally.

For excitation matrix $\alpha$, the first column shows how past events of both types excite type 0 (non-aggressive), and the second column shows how they excite type 1 (aggressive). An aggressive trade (type 1) causes a strong self-excitation (2.57), but non-aggressive trade has much smaller influence on aggressive one (0.52). Surprisingly, for non-aggressive trade, cross-excitation from aggressive to non-aggressive (15.85) is higher than its self-excitation. This reflects aggressive trade events have significant market influence and might cause volatility towards trader behaviors. 

Each value in the decay matrix $\beta$ represents how quickly the effect of a past event of type fades when it influences the intensity of current type. A non-aggressive trade (type 0) decays with a moderate speed when it influences another non-aggressive trade (\( \beta = 10.55 \)). When an aggressive trade (type 1) influences non-aggressive activity (\( \beta = 18.48 \)), the effect decays faster. Combined with the $\alpha = 15.85$, it suggests that aggressive trade has a short but noticeable impact for non-aggressive trade in the market. On the other hand, a non-aggressive trade has almost no lasting effect on aggressive trades, as shown by the very fast decay rate (\( \beta = 62.32 \)). Lastly, the self-decay for aggressive trades (\( \beta = 14.76 \)) is moderate, meaning aggressive trades cluster, but the effect also wears off gradually.

% !!need careful explain of this plot
Figure~\ref{fig:neuralhp-intensity} shows the result of the intensity estimation based on the fitted model and the hidden states from GRU. It is generated by computing the intensity at evenly spaced timestamps over the trading period. The model uses the hidden state $h_t$ from GRU at each time point, along with the event history up to that point, to calculate the intensity values. 

The top plot the sum of intensities $\sum_{m} \lambda_k(t)$ across both event types at every time step. The small purple markers indicate when actual events occurred. The middle plot shows the intensity for type 0 (non-aggressive). It has strong fluctuations and many large peaks. It aligns well with the red event markers. As can be seen in the bottom plot, it is type 1 (aggressive) intensity, which is generally much lower than non-aggressive trade events. Still, many aggressive trade events align with sharp local peaks, meaning the model successfully captures those trades. In conclusion, the estimation results show that the model correctly adjusts intensity to reflect aggressive trade likelihood.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\linewidth]{figures/hp_estimation.png}
    \caption{Estimated intensity functions for each event type. Red markers indicate actual event times.}
    \label{fig:neuralhp-intensity}
\end{figure}

%------------ prediction -------------
After getting the estimated parameters from the training phase, we test the Neural Hawkes Process on out-of-sample data. The input for prediction comes from the test output dataset of the XGBoost classifier. This XGBoost, as discussed before, was designed to contain more aggressive trades by predicting as many positives as possible, helping us balance the class better during prediction. It includes market features such as spread ($S$), mid-price ($M$), volume at best ask and bid ($V_A^1$, $V_B^1$), short-term average changes ($\bar{\delta}_S$, $\bar{\delta}_M$), volatilities ($\sigma_S$, $\sigma_M$), and volume ratio ($r_V$). These can all be fetched directly from Snowflake or calculated by these raw data. These features are used to extract hidden states from the GRU, and the corresponding timestamps ($T$) are passed into the Hawkes process to compute event intensities using the previously estimated parameters.

We first conduct prediction on a sample from 2025-02-18 13:30:04.710 to 2025-02-18 13:59:53.060. The model finally predicts 38 points as aggressive trades. In reality, 23 of them are actual aggressive trades during this time window. It is acceptable because we are more tolerant to false positives than false negatives. The prediction result is in Figure~\ref{fig:nhp-aflag}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\linewidth]{figures/aflag_NHP_181330.png}
    \caption{Comparison of true vs. predicted $\bar{\alpha}$ from neural Hawkes process. 
    The blue '+' markers show the true class labels, and the orange '+' markers show the predicted ones. To make the plot easier to read, the predicted values are moved down by 0.05 on the y-axis.
    }
    \label{fig:nhp-aflag}
\end{figure}

When it comes to performance evaluation, relying on exact matching metrics like confusion matrix, precision, or recall is not sufficient. In our case, the model predicts 38 aggressive trades while only 23 are truly observed. This difference is expected because the neural Hawkes process simulates events based on the fitted intensity. Its purpose is to capture realistic market patterns, rather than replicate the exact event sequence. In the MN backtesting context, it is more important to match the overall temporal behavior and shape of trading activity than to align precisely with every timestamp. Below, we explain the results of more appropriate evaluation metrics, as summarized in Table~\ref{tb:Evaluation Metrics}.


%----------Temporal Alignment---------
The \textbf{Dynamic Time Warping (DTW)} distance is 23.0, with a normalized DTW value of 0.00297 in Table~\ref{tab:dtw}. This is very low, which shows that the predicted trade activity follows a very similar time pattern as the actual aggressive trades. The alignment path length is 15,464, and the diagonal ratio is 1.995. A ratio close to 2 means the predicted and actual sequences align almost one-to-one. These results confirm that the model learns the shape and rhythm of the trading activity well.
\begin{table}[H]
    \centering
    \caption{Dynamic Time Warping (DTW) Results} \label{tab:dtw}
    \label{tb:dtw-results}
    \begin{tabular}{lr}
    \toprule
    Metric & Value \\
    \midrule
    DTW Distance & 23.0 \\
    Normalized DTW Distance & 0.00297 \\
    Alignment Path Length & 15,464 \\
    Diagonal Ratio & 1.995 \\
    \bottomrule
    \end{tabular}
\end{table}

The \textbf{Wasserstein distance} is 0.0019 in Table~\ref{tb:wasserstein-results}, and the normalized value is also 0.0019 out of a possible maximum distance of 1.0. This is extremely low. It means that the distribution of predicted event times is almost the same as the real distribution. This is a very strong result, showing that even if the model doesn't predict every individual event correctly, the timing and density of trades over time is very accurate.
\begin{table}[H]
    \centering
    \caption{Wasserstein Distance Results}
    \label{tb:wasserstein-results}
    \begin{tabular}{lr}
    \toprule
    Metric & Value \\
    \midrule
    Wasserstein Distance & 0.0019 \\
    Normalized Distance & 0.0019 \\
    Maximum Possible Distance & 1.0000 \\
    \bottomrule
    \end{tabular}
\end{table}

% For the \textbf{Fréchet distance} in Table~\ref{tb:frechet-results}, the value is 120.98 and the normalized value is 0.4263. This is a higher value compared to DTW or Wasserstein, which suggests that while the general pattern is followed, the paths are not perfectly smooth or identical. Still, it is within an acceptable range for modeling real-world stochastic processes. The model predicts 37 event intervals, while there are 22 in reality, indicating a slight over-generation of events. However, the Kolmogorov-Smirnov (KS) test p-value is 0.1239, which means the model's event interval distribution is not statistically different from the true one at common significance levels.
% \begin{table}[H]
%     \centering
%     \caption{Fréchet Distance and Distribution Comparison}
%     \label{tb:frechet-results}
%     \begin{tabular}{lr}
%     \toprule
%     Metric & Value \\
%     \midrule
%     Fréchet Distance & 120.98 \\
%     Fréchet Distance (Normalized) & 0.4263 \\
%     Wasserstein Distance (Reference) & 30.99 \\
%     KS Test p-value & 0.124 \\
%     Actual Intervals & 22 \\
%     Predicted Intervals & 37 \\
%     \bottomrule
%     \end{tabular}
% \end{table}

In summary, these metrics show that our model captures the dynamics and timing patterns of aggressive trades well. While not perfect in predicting exact events, the low DTW and Wasserstein distances confirm strong temporal alignment and distributional similarity. This supports the usefulness of our model for predicting trader behavior in backtesting environments.



%------clustering-----------
To further evaluate the realism of the predicted aggressive trades, we assess the clustering behavior using two statistical tools: the Allan Factor and Ripley's K/L functions. These methods help us understand whether the predicted results have realistic temporal clusters like the reality in the market, or whether they behave more like random noise.

The \textbf{Allan factor} measures event clustering over different time windows. A value of AF greater than 1 indicates clustering, while AF close to 1 suggests a random process. As can be seen in Table~\ref{tb:allan-factor}, for the true aggressive trades ($\bar{\alpha}_\text{true}$), the average Allan Factor is 1.0698. The Allan Factors across different window sizes are as follows: 1.044 for window size 2, 1.044 for window 5, 0.958 for window 10, 1.090 for window 20, and 1.050 for window 50. This suggests consistent clustering in the actual events. For the predicted aggressive trades ($\bar{\alpha}_\text{pred}$), the average Allan Factor is higher, at 1.2687. The Allan Factors at various window sizes are: 0.869 at window size 2, 1.290 at window 5, 1.159 at window 10, 1.346 at window 20, and 1.722 at window 50. These values show stronger clustering in the prediction, especially at longer windows. This is reasonable, as the neural Hawkes process is designed to model self-exciting behavior especially.

\begin{table}[H]
    \centering
    \caption{Allan Factor Results for Aggressive Trade Clustering}
    \label{tb:allan-factor}
    \begin{tabular}{lcc}
    \toprule
    \textbf{Window Size} & $\bar{\alpha}_\text{true}$ & $\bar{\alpha}_\text{pred}$\\
    \midrule
    2   & 1.044 & 0.869 \\
    5   & 1.044 & 1.290 \\
    10  & 0.958 & 1.159 \\
    20  & 1.090 & 1.346 \\
    50  & 1.050 & 1.722 \\
    \midrule
    \textbf{Average AF} & 1.0698 & 1.2687 \\
    \textbf{Number of Events} & 23 & 38 \\
    \textbf{Event Rate} & 0.00297 & 0.00490 \\
    \bottomrule
    \end{tabular}
\end{table}

We also use \textbf{Ripley's K and L functions} to further test clustering. These functions evaluate how events are spread in time. If the \( L(r) \) value is greater than 0, the process is considered clustered; if it is near 0, the process is closer to random. In Table~\ref{tb:ripley-l}, for $\bar{\alpha}_\text{true}$, the number of events is 23, the event intensity is 0.0128 events per second, and the average \( L(r) \) value is 22.76. The values at 1s, 2s, and 5s distances are 12.61, 11.61, and 15.42 respectively. For $\bar{\alpha}_\text{pred}$, the number of events is 38, the intensity is 0.0211 events per second, and the average \( L(r) \) is 31.04. The values at the same distances are 13.96 at 1s, 15.45 at 2s, and 22.42 at 5s. These consistently higher \( L(r) \) values again show stronger clustering in the predicted trades. In the Figure~\ref{fig:ripley-kl}, the blue curve corresponds to the actual aggressive trades, while the orange curve shows the predicted trades generated by the neural Hawkes model. We observe that both curves are consistently above the baseline, indicating clustering behavior in both series. The predicted trades closely match the clustering pattern of the actual trades, particularly at shorter distances. This suggests that the model captures the clustering of aggressive trading activity well.

In conclusion, both Allan Factor and Ripley's L function results suggest that the predicted aggressive trades exhibit realistic clustering behavior. While the predicted clustering is slightly stronger than in the true data, this is a natural result of the self-exciting nature of the Hawkes process.

\begin{table}[H]
    \centering
    \caption{Ripley's L Function Summary}
    \label{tb:ripley-l}
    \begin{tabular}{lcc}
    \toprule
    \textbf{Metric} & $\bar{\alpha}_\text{true}$ & $\bar{\alpha}_\text{pred}$ \\
    \midrule
    Number of Events & 23 & 38 \\
    Event Intensity (events/sec) & 0.0128 & 0.0211 \\
    Average \( L(r) \) & 22.76 & 31.04 \\
    \( L(1s) \) & 12.61 & 13.96 \\
    \( L(2s) \) & 11.61 & 15.45 \\
    \( L(5s) \) & 15.42 & 22.42 \\
    \bottomrule
    \end{tabular}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{figures/RIPLEY_181330.png}
    \caption{Ripley's K and L functions comparing real and predicted aggressive trades. Values above the dashed line in the \( L(r) \) plot indicate clustering behavior. Both actual and predicted series exhibit clustering across all distances. The predicted trades show stronger clustering, especially at larger distances, which is consistent with the self-exciting nature of the Hawkes process.}
    \label{fig:ripley-kl}
\end{figure}



%----------------------ACF--------------------
Next, we analyze the \textbf{autocorrelation} structure of both the actual and predicted aggressive trade series to assess whether the neural Hawkes process model shows the temporal dependence between trades. The Autocorrelation Function (ACF) and Partial Autocorrelation Function (PACF) plots are shown in Figure~\ref{fig:acf-pacf}. For the actual aggressive trade series ($\bar{\alpha}_\text{true}$), the lag-1 autocorrelation is 0.0842, showing weak but positive short-term dependence. The values quickly drop near zero at higher lags. For example lag-5 and lag-10 both are -0.0030. In total, 6 lags are statistically significant, and the Ljung-Box test p-value is essentially zero. This indicates that even though the autocorrelations are small, the actual process does have significant temporal structure. Next we test if the temporal structure also exists in our prediction. For the predicted series ($\bar{\alpha}_\text{pred}$), the lag-1 autocorrelation is 0.0744, which is very close to the actual series. Lag-5 and lag-10 values are -0.0049, also similar to the actual values. There are 4 significant lags, and the Ljung-Box test again returns a p-value closing to 0. This indicates the presence of temporal dependence.

These results suggest that the neural Hawkes process produces a time series with similar short-term dependency structure as the actual trader behaviors in the real market. It is fair to say the neural Hawkes process is capable of capturing temporal structure in aggressive trade patterns.

% \textbf{Cross-correlation Analysis:} The cross-correlation between the true and predicted series is also computed. The maximum cross-correlation value is 0.0980, occurring at lag 49. The zero-lag correlation is 0.0301. Although the absolute correlation is small, this shows that the predicted sequence partially aligns with the actual series, especially with a slight time shift.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\linewidth]{figures/ACF_181330.png}
    \caption{Autocorrelation (ACF) and Partial Autocorrelation (PACF) plots of actual and predicted aggressive trade series.}
    \label{fig:acf-pacf}
\end{figure}


%----------------Distributional Test-------------

Furthermore, to evaluate how well the predicted aggressive trade events match the statistical distribution of actual trades, we perform distributional tests by the \textbf{Kolmogorov-Smirnov (KS) test}. 
% and the \textbf{Kullback-Leibler (KL) divergence}.

The KS test is used to compare the cumulative distributions of two sample sets. It returns a test statistic and a p-value. If the p-value is below 0.05, the distributions are considered significantly different. In our case as shown in Table~\ref{tb:ks-test}, the KS statistic is 0.0019 and the p-value is 1.0000, indicating that there is no statistically significant difference between the predicted and actual event distributions. The actual proportion of aggressive trades is 0.0030, and the predicted proportion is 0.0049. The difference between them is only 0.0019. This result shows that the neural Hawkes model accurately matches the distribution of aggressive trade occurrence over time.

\begin{table}[H]
    \centering
    \caption{Kolmogorov--Smirnov Test Results}
    \label{tb:ks-test}
    \begin{tabular}{lr}
    \toprule
    \textbf{Metric} & \textbf{Value} \\
    \midrule
    KS Statistic & 0.0019 \\
    p-value & 1.0000 \\
    Significant ($p < 0.05$) & False \\
    Actual Proportion & 0.0030 \\
    Predicted Proportion & 0.0049 \\
    Proportion Difference & 0.0019 \\
    \bottomrule
    \end{tabular}
\end{table}

% KL divergence is a measure of how one probability distribution differs from another. We compute the KL divergence in both directions between the windowed count distributions of the predicted and actual events. 

% The value of KL (actual $\parallel$ predicted) is 7.7609 bits, while KL (predicted $\parallel$ actual) is 2.6656 bits. The symmetric KL divergence is 5.2132 bits. These values are relatively moderate, indicating that the predicted distribution is somewhat more peaked or uneven than the actual one. Still, the predicted distribution resembles the actual distribution well enough for backtesting purposes. Lower KL divergence values generally mean higher similarity, and in our case the distributional shape is captured to a reasonable degree.

% \begin{figure}[H]
%     \centering
%     \includegraphics[width=0.95\linewidth]{figures/KL_181330.png}
%     \caption{KL divergence plot for event count distributions (predicted vs actual).}
%     \label{fig:kl-divergence}
% \end{figure}

% \begin{table}[H]
%     \centering
%     \caption{Kullback--Leibler Divergence Between Actual and Predicted Distributions}
%     \label{tb:kl-divergence}
%     \begin{tabular}{lr}
%     \toprule
%     \textbf{Metric} & \textbf{Value (bits)} \\
%     \midrule
%     KL(actual $\parallel$ predicted) & 7.7609 \\
%     KL(predicted $\parallel$ actual) & 2.6656 \\
%     Symmetric KL Divergence & 5.2132 \\
%     \bottomrule
%     \end{tabular}
% \end{table}


%---------Conclusion-----------
Overall, all these metrics, including DTW, Wasserstein distance, Allan factor, Ripley's K and L functions, autocorrelation and KS test confirm that the neural Hawkes process not only models the timing and clustering of events, but also captures the underlying distributional structure of aggressive trade frequency. The Neural Hawkes Process with XGBoost filter and GRU kernel captures realistic and reliable patterns in aggressive trade. It shows interpretable dynamics like short-term excitation, quick decay, and clustering, especially for aggressive trades. This supports our idea that using our framework not only captures overall market features and temporal dependency, but also gives more robustness and control than black-box classifiers.

\section{Overall Data Flow}
Figure~\ref{fig:data-flow-diagram} illustrates the full data flow of the framework, including KMeansSMOTE XGBoost and the Neural Hawkes Process. On the left side, training data A1 from Day 1 is used to train the KM-XGBoost classifier. KMeansSMOTE is applied to improve class imbalance. Normally the final training dataset contains  over 400,000 rows and 13 columns. The trained model is then used to filter aggressive trades on window-based (like 30 minutes or 1 hour) test data B1 from Day 2, producing the output data B2.

On neural Hawkes process side, estimated data A2 is functioned by an anomaly detection for class balance. Then it is processed by a GRU model to extract hidden states. After that, estimation of the parameters is implemented. The filtered data B2 from the XGBoost stage is used to compute the event intensities on B2 timestamps. These intensities are passed through Ogata's thinning algorithm to promote the final aggressive trade predictions.

The final prediction result is evaluated against the true events using various metrics, including dynamic time warping, Wasserstein distance, Allan factor, Ripley's K and L functions, autocorrelation (ACF/PACF), and KS test. These metrics cover different dimensions such as temporal dependency, clustering, and distribution.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/data_flow1.png}
    \caption{Data flow of the full pipeline from raw data to final prediction.}
    \label{fig:data-flow-diagram}
\end{figure}